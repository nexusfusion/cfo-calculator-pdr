# 7.3 Suite Analytics Dashboards

This section defines the analytics dashboards that provide business intelligence for the CFO Business Intelligence Calculator Suite. These dashboards aggregate events from Section 7.2 to surface insights on usage, conversions, performance, and feature adoption across all calculators and tiers.

---

## Dashboard Overview

**Purpose**: Transform raw analytics events into actionable business metrics for:
- Product managers (feature prioritization, roadmap decisions)
- Marketing (traffic source ROI, conversion optimization)
- Engineering (performance monitoring, error tracking)
- Finance (revenue attribution, pricing validation)

**Implementation**: Dashboards built on analytics data warehouse (ClickHouse, BigQuery, or Postgres + Metabase/Tableau).

**Refresh cadence**:
- Real-time dashboards: Every 5 minutes (for monitoring critical metrics)
- Business dashboards: Hourly or daily (for trend analysis)

---

## 1. Calculator Funnel Dashboard

### Purpose

Track user journey from initial view through calculation to export for each calculator. Identify drop-off points and conversion bottlenecks.

### Key Metrics

**Funnel stages**:
1. **Views**: calculator_viewed events (funnel entry)
2. **Calculations**: calculator_calculated events (engagement)
3. **Exports**: export_downloaded events (conversion)

**Conversion rates**:
- **View-to-calculation rate**: (calculator_calculated / calculator_viewed) × 100
  - Example: 65% of viewers perform at least one calculation
  - Target: >60% (high engagement indicator)

- **Calculation-to-export rate**: (export_downloaded / calculator_calculated) × 100
  - Example: 15% of calculations result in export
  - Target: >10% (export indicates serious usage)

- **View-to-export rate**: (export_downloaded / calculator_viewed) × 100
  - Example: 9.8% end-to-end conversion
  - Target: >8% (qualified users complete full journey)

**Per-calculator breakdown**:
| Calculator | Views | Calculations | Exports | View→Calc | Calc→Export | View→Export |
|------------|-------|--------------|---------|-----------|-------------|-------------|
| Business Loan DSCR | 12,450 | 8,100 | 1,220 | 65.1% | 15.1% | 9.8% |
| Cash Runway | 8,320 | 5,600 | 840 | 67.3% | 15.0% | 10.1% |
| Breakeven Margin | 6,780 | 4,200 | 520 | 61.9% | 12.4% | 7.7% |
| Valuation Models | 4,560 | 2,900 | 580 | 63.6% | 20.0% | 12.7% |
| Equipment Lease | 3,890 | 2,500 | 310 | 64.3% | 12.4% | 8.0% |

**Drop-off analysis**:
- **High view, low calculation**: Poor calculator UX or unclear value proposition
- **High calculation, low export**: Free tier users hitting watermark (upgrade opportunity)
- **High export**: Power users (likely Pro tier candidates)

### Filters

- **Date range**: Last 7 days, Last 30 days, Last 90 days, Custom range
- **Tier**: All, Free, Pro, AI, B2B
- **Calculator**: All, or specific calculator slug
- **Referrer**: All, Organic, Paid, Affiliate, Direct

### Charts

**1. Funnel visualization**:
```
Calculator Funnel (Last 30 Days)
┌─────────────────────────────────┐
│ Views           35,000   100%   │
│   ▼                              │
│ Calculations    23,300    66.6% │
│   ▼                              │
│ Exports          3,470    15.0% │
│   ▼                              │
│ End-to-End                 9.9% │
└─────────────────────────────────┘
```

**2. Trend line chart**:
- X-axis: Date
- Y-axis: Event count
- Lines: calculator_viewed (blue), calculator_calculated (green), export_downloaded (orange)
- Purpose: Spot trends (growing usage, declining exports)

**3. Per-calculator bar chart**:
- X-axis: Calculator name
- Y-axis: Conversion rate (%)
- Bars: View→Calc rate, Calc→Export rate
- Purpose: Compare calculator performance

### Usage

**Questions this dashboard answers**:
- Which calculator has the highest engagement (calculation rate)?
- Where do users drop off in the funnel?
- Is conversion improving over time (trend analysis)?
- Do paid search users convert better than organic (referrer comparison)?

---

## 2. Tier Conversion Dashboard

### Purpose

Track Free → Pro and Pro → AI tier upgrades. Measure effectiveness of upgrade prompts and identify high-converting triggers.

### Key Metrics

**Conversion rates**:
- **Free → Pro conversion rate**: (upgrade_completed with target_tier=pro / unique Free users) × 100
  - Example: 4.2% of Free users upgrade to Pro
  - Target: >3% monthly (sustainable growth)

- **Pro → AI conversion rate**: (upgrade_completed with target_tier=ai / unique Pro users) × 100
  - Example: 18% of Pro users add AI
  - Target: >15% (AI add-on adoption)

- **Trial → Paid conversion rate**: (paid subscriptions / trial starts) × 100
  - Example: 35% of Pro trials convert to paid
  - Target: >30% (healthy trial conversion)

**Upgrade prompt effectiveness**:
- **Prompt click-through rate**: (upgrade_prompt_clicked / upgrade_prompt_shown) × 100
  - Example: 8.5% of prompts result in clicks
  - Target: >6% (effective messaging)

- **Prompt → Completion rate**: (upgrade_completed / upgrade_prompt_shown) × 100
  - Example: 1.2% of prompts result in completed upgrades
  - Target: >1% (healthy conversion)

**Time to conversion**:
- **Days from signup to upgrade**: Average days between user signup and first upgrade_completed
  - Example: 12 days (median), 21 days (mean)
  - Target: <14 days (faster conversion = better onboarding)

**Trigger breakdown**:
| Trigger Reason | Prompts Shown | Clicks | Completions | Click Rate | Completion Rate |
|----------------|---------------|--------|-------------|------------|-----------------|
| locked_metric | 8,450 | 890 | 145 | 10.5% | 1.7% |
| add_scenario | 6,320 | 510 | 98 | 8.1% | 1.6% |
| clean_export | 4,780 | 380 | 72 | 7.9% | 1.5% |
| ai_request | 3,120 | 220 | 56 | 7.1% | 1.8% |

**Insights**:
- "locked_metric" has highest click rate (10.5%) → advanced metrics are strong value prop
- "ai_request" has highest completion rate (1.8%) → AI users are motivated buyers

### Filters

- **Date range**: Last 7 days, Last 30 days, Last 90 days, Custom range
- **Calculator**: All, or specific calculator (attribute upgrade to calculator context)
- **Trigger reason**: All, locked_metric, add_scenario, clean_export, ai_request
- **Target tier**: Pro, AI

### Charts

**1. Conversion funnel**:
```
Free → Pro Upgrade Funnel (Last 30 Days)
┌─────────────────────────────────────┐
│ Upgrade Prompts Shown    22,670     │
│   ▼                                  │
│ Clicks                    2,000  8.8%│
│   ▼                                  │
│ Checkout Started          1,200 60.0%│
│   ▼                                  │
│ Completed Upgrades          371 30.9%│
│   ▼                                  │
│ Overall Conversion              1.6% │
└─────────────────────────────────────┘
```

**2. Cohort retention table**:
| Cohort | Month 0 | Month 1 | Month 2 | Month 3 | Month 6 | Month 12 |
|--------|---------|---------|---------|---------|---------|----------|
| Jan 2025 | 100% | 85% | 78% | 72% | 65% | 58% |
| Feb 2025 | 100% | 87% | 80% | 74% | - | - |
| Mar 2025 | 100% | 89% | 82% | - | - | - |

Purpose: Track retention after upgrade (are Pro users staying subscribed?)

**3. Trigger breakdown pie chart**:
- Slices: locked_metric (45%), add_scenario (30%), clean_export (18%), ai_request (7%)
- Purpose: Show which triggers drive most conversions

### Usage

**Questions this dashboard answers**:
- What percentage of Free users convert to Pro each month?
- Which upgrade trigger has the highest ROI?
- How long does it take for users to upgrade after signup?
- Are trial users converting to paid subscriptions?
- Which calculator context drives most upgrades (e.g., DSCR calculator → Pro)?

---

## 3. AI Usage Dashboard

### Purpose

Monitor AI feature adoption, performance, and cost. Validate AI tier pricing and identify optimization opportunities.

### Key Metrics

**AI request volume**:
- **Total AI requests per month**: Sum of ai_narrative_requested events
  - Example: 12,450 requests across all AI tier users

- **AI requests per user**: (Total AI requests / unique AI tier users)
  - Example: 8.3 requests per user per month
  - Target: >5 requests (justify $20/month AI pricing)
  - Limit: 50 requests per user per month (hard cap)

**AI success rate**:
- **Success rate**: (ai_narrative_displayed / ai_narrative_requested) × 100
  - Example: 96.5% of requests succeed
  - Target: >95% (high reliability)

**AI performance**:
- **p50 latency**: Median response time from ai_narrative_requested to ai_narrative_displayed
  - Example: 1.8 seconds
  - Target: <2 seconds (feels fast)

- **p95 latency**: 95th percentile response time
  - Example: 2.9 seconds
  - Target: <3 seconds (per Section 1.6 SLAs)

- **p99 latency**: 99th percentile response time
  - Example: 4.2 seconds
  - Acceptable: <5 seconds (rare slow requests tolerable)

**AI cost tracking**:
- **Cost per request**: Average LLM API cost per successful request
  - Example: $0.12 per request

- **Total monthly cost**: Sum of AI request costs
  - Example: $1,494 for 12,450 requests

- **Cost per user**: (Total monthly cost / unique AI tier users)
  - Example: $1.00 per user (well below $20 pricing, healthy margin)

**Request type breakdown**:
| Request Type | Count | Percentage | Avg Latency | Success Rate |
|--------------|-------|------------|-------------|--------------|
| explain_result | 8,715 | 70% | 1.6s | 97.2% |
| suggest_scenario | 2,490 | 20% | 3.2s | 94.8% |
| risk_commentary | 1,245 | 10% | 2.1s | 96.0% |

**Insights**:
- "explain_result" is most popular (70%) and fastest (1.6s)
- "suggest_scenario" is slower (3.2s) → may need optimization

### Filters

- **Date range**: Last 7 days, Last 30 days, Last 90 days, Custom range
- **Tier**: AI only, or include B2B (if B2B has AI enabled)
- **Calculator**: All, or specific calculator
- **Request type**: All, explain_result, suggest_scenario, risk_commentary

### Charts

**1. AI usage over time (line chart)**:
- X-axis: Date
- Y-axis: Request count
- Lines: Total requests, Successful requests, Failed requests
- Purpose: Spot usage trends and error spikes

**2. Success rate gauge**:
```
AI Success Rate (Last 30 Days)
┌──────────────────┐
│   ████████░░     │
│      96.5%       │
│   Target: >95%   │
└──────────────────┘
```

**3. Latency distribution histogram**:
- X-axis: Response time (seconds)
- Y-axis: Request count
- Bins: 0-1s, 1-2s, 2-3s, 3-4s, 4-5s, >5s
- Purpose: Identify outliers (requests >5s)

### Usage

**Questions this dashboard answers**:
- Are AI tier users actually using AI features (>5 requests/month)?
- Is AI performance meeting SLAs (p95 <3s)?
- Which AI request types are most popular?
- Is AI cost per user sustainable (<$5 COGS for $20 pricing)?
- Are there error spikes that need investigation?

---

## 4. Export Dashboard

### Purpose

Track export usage, format preferences, and performance. Identify Free → Pro conversion opportunities (watermarked exports).

### Key Metrics

**Export volume**:
- **Total exports per month**: Sum of export_downloaded events
  - Example: 8,340 exports across all tiers

- **Exports per tier**:
  - Free tier: 3,250 exports (watermarked)
  - Pro tier: 4,120 exports (clean)
  - AI tier: 970 exports (clean)

**Export format preferences**:
| Format | Count | Percentage | Avg Generation Time | Failure Rate |
|--------|-------|------------|---------------------|--------------|
| PDF | 5,004 | 60% | 2.3s | 1.2% |
| CSV | 2,502 | 30% | 0.5s | 0.3% |
| Excel | 834 | 10% | 1.8s | 0.9% |

**Export generation performance**:
- **p50 generation time**: Median time from export_requested to export_generated
  - PDF: 2.1 seconds
  - CSV: 0.4 seconds
  - Excel: 1.6 seconds

- **p95 generation time**: 95th percentile
  - PDF: 2.8 seconds (target: <3s, ✓ passing)
  - CSV: 0.7 seconds
  - Excel: 2.4 seconds

- **p99 generation time**: 99th percentile
  - PDF: 4.5 seconds (rare slow exports acceptable)
  - CSV: 1.1 seconds
  - Excel: 3.2 seconds

**Export failure rate**:
- **Failure rate**: (export_requested - export_generated) / export_requested × 100
  - PDF: 1.2% failure rate (timeout or rendering errors)
  - CSV: 0.3% failure rate (calculation errors)
  - Excel: 0.9% failure rate

**Top exported calculators**:
| Calculator | Exports | Percentage | Avg Format (PDF/CSV/Excel) |
|------------|---------|------------|----------------------------|
| Business Loan DSCR | 2,450 | 29% | 65% / 25% / 10% |
| Valuation Models | 1,670 | 20% | 80% / 15% / 5% |
| Cash Runway | 1,250 | 15% | 50% / 40% / 10% |
| Breakeven Margin | 1,040 | 12% | 55% / 35% / 10% |
| Equipment Lease | 830 | 10% | 60% / 30% / 10% |

### Filters

- **Date range**: Last 7 days, Last 30 days, Last 90 days, Custom range
- **Tier**: All, Free, Pro, AI, B2B
- **Format**: All, PDF, CSV, Excel
- **Calculator**: All, or specific calculator

### Charts

**1. Export volume over time (stacked area chart)**:
- X-axis: Date
- Y-axis: Export count
- Stacks: PDF (blue), CSV (green), Excel (orange)
- Purpose: Show format trends over time

**2. Format preference pie chart**:
```
Export Format Distribution
┌─────────────────┐
│  PDF    60%  ██ │
│  CSV    30%  █  │
│  Excel  10%  ░  │
└─────────────────┘
```

**3. Generation time distribution (box plot)**:
- X-axis: Format (PDF, CSV, Excel)
- Y-axis: Generation time (seconds)
- Box: p25, p50, p75
- Whiskers: p5, p95
- Purpose: Compare performance across formats

### Usage

**Questions this dashboard answers**:
- Which export format is most popular (PDF dominates)?
- Is export generation meeting performance targets (p95 <3s)?
- Which calculators drive most exports (DSCR, Valuation)?
- Are Free tier users exporting frequently (upgrade opportunity)?
- Are there export error spikes that need fixing?

---

## 5. Scenario Usage Dashboard

### Purpose

Measure Pro tier feature adoption. Track multi-scenario usage to validate Pro tier value proposition ($29/month).

### Key Metrics

**Average scenarios per session**:
- **Free tier**: 1.0 scenarios (always, limited to single scenario)
- **Pro tier**: 2.3 scenarios per session (multi-scenario adoption)
- **AI tier**: 2.8 scenarios per session (higher engagement)
- **B2B tier**: 3.5 scenarios per session (professional use cases)

**Scenario save rate**:
- **Save rate**: (sessions with scenario_created / total calculator sessions) × 100
  - Example: 35% of Pro sessions create additional scenarios
  - Target: >30% (Pro users utilizing feature)

**Multi-scenario comparison usage**:
- **Percentage using 2+ scenarios**: (Pro users with 2+ scenarios / total Pro users) × 100
  - Example: 45% of Pro users compare multiple scenarios
  - Target: >40% (core Pro value prop)

**Scenarios per calculator**:
| Calculator | Avg Scenarios (Pro) | % Using 2+ | % Using 5+ |
|------------|---------------------|------------|------------|
| Valuation Models | 3.8 | 72% | 28% |
| Business Loan DSCR | 2.9 | 58% | 15% |
| Cash Runway | 2.5 | 52% | 12% |
| Breakeven Margin | 1.8 | 38% | 8% |
| Equipment Lease | 1.6 | 32% | 5% |

**Insights**:
- Valuation calculators drive highest scenario usage (3.8 avg) → strong Pro fit
- Breakeven/Lease have lower usage → may not benefit from multi-scenario as much

**Scenario lifecycle**:
- **Average scenario lifespan**: Days from scenario_created to scenario_deleted
  - Example: 45 days (median), 120 days (mean)
  - Indicates: Users keep scenarios for months (long-term value)

### Filters

- **Date range**: Last 7 days, Last 30 days, Last 90 days, Custom range
- **Tier**: Pro, AI, B2B (exclude Free, they can't create scenarios)
- **Calculator**: All, or specific calculator

### Charts

**1. Scenario distribution histogram**:
- X-axis: Number of scenarios (1, 2, 3, 4, 5+)
- Y-axis: User count
- Bars: Free (always 1), Pro (distribution), AI (distribution)
- Purpose: Show multi-scenario adoption

**2. Per-calculator bar chart**:
- X-axis: Calculator name
- Y-axis: Average scenarios per session
- Bars: Pro tier (sorted descending)
- Purpose: Identify which calculators benefit from scenarios

**3. Scenario creation trend (line chart)**:
- X-axis: Date
- Y-axis: scenario_created event count
- Lines: Pro, AI, B2B
- Purpose: Track scenario feature adoption over time

### Usage

**Questions this dashboard answers**:
- Are Pro users creating multiple scenarios (justifying $29/month)?
- Which calculators drive highest scenario usage?
- Is scenario adoption growing over time?
- How long do users keep scenarios before deleting?

---

## Dashboard Implementation Notes

**Technology stack**:
- **Data warehouse**: ClickHouse (fast analytics) or BigQuery (managed, scalable)
- **Visualization**: Metabase (open-source), Tableau, or Looker
- **Real-time**: Grafana for monitoring dashboards (exports, AI performance)

**Refresh cadence**:
- **Real-time** (every 5 min): Error tracking, AI performance, export generation
- **Hourly**: Calculator funnel, tier conversion
- **Daily**: Scenario usage, export dashboard

**Access control**:
- Product managers: All dashboards (read-only)
- Engineering: All dashboards + error monitoring (write access to annotations)
- Marketing: Calculator funnel, tier conversion (read-only)
- Finance: Tier conversion, AI cost tracking (read-only)

**Alerting integration**:
- Connect dashboards to alerting system (Slack, PagerDuty)
- Example: Alert if Free → Pro conversion drops below 2% for 3 consecutive days

---

## Summary

These 5 analytics dashboards provide comprehensive business intelligence:
- **Calculator Funnel**: Track views → calculations → exports (engagement)
- **Tier Conversion**: Measure Free → Pro and Pro → AI upgrades (revenue)
- **AI Usage**: Monitor AI adoption, performance, cost (feature validation)
- **Export Dashboard**: Track export volume, formats, performance (key feature metric)
- **Scenario Usage**: Measure multi-scenario adoption (Pro tier validation)

All dashboards built on standard events from Section 7.2, refreshed hourly or real-time, with role-based access control.
