# 7.4 Error and Performance Monitoring

This section defines error tracking, performance monitoring, alerting thresholds, and observability tools for the CFO Business Intelligence Calculator Suite. Proactive monitoring ensures reliability targets (Section 1.6) are met and issues are detected before impacting users.

---

## Monitoring Philosophy

**Goals**:
- **Detect before users report**: Alerts fire before users experience degraded service
- **Root cause diagnosis**: Logs and metrics provide enough context to debug quickly
- **Performance SLA enforcement**: Automated alerts when p95 latency exceeds targets
- **Error budget tracking**: Monitor error rates against reliability goals (99.5% uptime)

**Implementation approach**:
- Server-side instrumentation (not just client-side, which misses backend failures)
- Structured logging (JSON format for machine parsing)
- Distributed tracing for multi-service requests (export generation, AI calls)
- Real-time dashboards with 5-minute refresh

---

## 1. Error Tracking

### Error Categories

**1. Calculation Engine Errors**

**What gets tracked**:
- Formula evaluation failures (division by zero, square root of negative, invalid inputs)
- Edge case errors (NaN, Infinity, null outputs)
- Timeout errors (calculation exceeds 10-second limit)
- Validation errors (inputs outside acceptable ranges)

**Error examples**:
- `CALCULATION_TIMEOUT`: Calculation exceeded 10-second server-side timeout
- `INVALID_INPUT_RANGE`: User input outside valid range (e.g., negative loan amount)
- `FORMULA_EVALUATION_ERROR`: JavaScript math error (e.g., Math.sqrt(-1) → NaN)
- `NAN_RESULT`: Calculation produced NaN due to invalid intermediate values

**What gets logged**:
```json
{
  "timestamp": "2025-11-17T21:45:32Z",
  "level": "error",
  "error_type": "CALCULATION_TIMEOUT",
  "error_message": "DSCR calculation exceeded 10-second timeout",
  "calculator_slug": "business-loan-dscr",
  "session_id": "550e8400-e29b-41d4-a716-446655440000",
  "user_id": null,
  "tier": "free",
  "inputs": {
    "principal": 500000,
    "termMonths": 240,
    "annualRate": 6.5
  },
  "stack_trace": "Error: Timeout\n  at calculateDSCR (dscr.ts:45)\n  ..."
}
```

**Response**:
- Show user-friendly error: "This calculation is taking too long. Please try simpler inputs or contact support."
- Log full error details server-side for debugging
- Fire event: `calculator_error` with error_code

---

**2. Export Generation Errors**

**What gets tracked**:
- PDF rendering failures (Puppeteer crash, memory limit exceeded)
- CSV assembly errors (data serialization failures)
- Excel generation errors (library errors, formatting failures)
- S3/R2 upload failures (network timeout, storage quota exceeded)
- Export timeout errors (generation exceeds 30-second limit)

**Error examples**:
- `PDF_RENDERING_TIMEOUT`: PDF generation exceeded 30-second timeout
- `S3_UPLOAD_FAILED`: Failed to upload export file to storage (network error)
- `EXPORT_DATA_SERIALIZATION_ERROR`: Invalid data format for CSV/Excel generation
- `MEMORY_LIMIT_EXCEEDED`: PDF rendering consumed >512MB memory, process killed

**What gets logged**:
```json
{
  "timestamp": "2025-11-17T21:46:10Z",
  "level": "error",
  "error_type": "PDF_RENDERING_TIMEOUT",
  "error_message": "PDF export exceeded 30-second timeout",
  "calculator_slug": "business-loan-dscr",
  "session_id": "550e8400-e29b-41d4-a716-446655440000",
  "user_id": "e8f5a3c2-1234-5678-9abc-def012345678",
  "tier": "pro",
  "export_format": "pdf",
  "scenario_count": 5,
  "generation_start_time": "2025-11-17T21:45:40Z",
  "generation_duration_ms": 30125,
  "stack_trace": "Error: Timeout\n  at generatePDF (export.ts:78)\n  ..."
}
```

**Response**:
- Show user-friendly error: "Export failed. Please try again or contact support."
- Retry once automatically (if transient network error)
- Fire event: `export_error` with error_code
- Alert if error rate >5% in 5 minutes

---

**3. AI Service Errors**

**What gets tracked**:
- LLM API timeouts (no response within 30 seconds)
- LLM API rate limits (429 status from provider)
- LLM API failures (500 errors from provider)
- Invalid AI responses (malformed JSON, unexpected format)
- AI request quota exceeded (user hit 50 requests/month limit)

**Error examples**:
- `AI_API_TIMEOUT`: LLM API did not respond within 30 seconds
- `AI_API_RATE_LIMIT`: LLM provider rate limit exceeded (429 status)
- `AI_API_ERROR`: LLM provider returned 500 error
- `AI_QUOTA_EXCEEDED`: User has used 50/50 AI requests this month
- `AI_RESPONSE_INVALID`: LLM returned malformed or unparsable response

**What gets logged**:
```json
{
  "timestamp": "2025-11-17T21:47:25Z",
  "level": "error",
  "error_type": "AI_API_RATE_LIMIT",
  "error_message": "OpenAI API rate limit exceeded (429)",
  "calculator_slug": "business-loan-dscr",
  "session_id": "550e8400-e29b-41d4-a716-446655440000",
  "user_id": "e8f5a3c2-1234-5678-9abc-def012345678",
  "tier": "ai",
  "ai_request_type": "explain_result",
  "ai_provider": "openai",
  "ai_model": "gpt-4-turbo",
  "api_status_code": 429,
  "retry_after_seconds": 60
}
```

**Response**:
- Show user-friendly error: "AI is temporarily unavailable. Please try again in a moment."
- Retry with exponential backoff (wait 60s, then retry)
- Fire event: `ai_error` with error_code
- Alert if AI error rate >10% in 5 minutes

---

**4. Client-Side Errors**

**What gets tracked**:
- JavaScript exceptions (unhandled promise rejections, runtime errors)
- Network request failures (API timeouts, 500 errors)
- Client-side timeout errors (API call exceeded 10-second timeout)
- Browser compatibility errors (unsupported features)

**Error examples**:
- `JS_RUNTIME_ERROR`: Unhandled JavaScript exception in client
- `API_REQUEST_TIMEOUT`: Client-side API request exceeded 10-second timeout
- `API_REQUEST_FAILED`: API returned 500 error
- `NETWORK_ERROR`: Client network connection lost

**What gets logged**:
```json
{
  "timestamp": "2025-11-17T21:48:00Z",
  "level": "error",
  "error_type": "JS_RUNTIME_ERROR",
  "error_message": "Cannot read property 'dscr' of undefined",
  "calculator_slug": "business-loan-dscr",
  "session_id": "550e8400-e29b-41d4-a716-446655440000",
  "user_id": null,
  "tier": "free",
  "user_agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) ...",
  "browser": "Chrome 120.0",
  "stack_trace": "TypeError: Cannot read property 'dscr' of undefined\n  at ResultsCard.tsx:42\n  ..."
}
```

**Response**:
- Show user-friendly error boundary: "Something went wrong. Please refresh the page."
- Log error to monitoring service (Sentry, Datadog)
- Fire event: `client_error` with error_code
- Alert if error rate >5% in 5 minutes

---

### Error Logging Best Practices

**Structured logging format** (JSON):
```json
{
  "timestamp": "ISO 8601 UTC",
  "level": "error|warn|info",
  "error_type": "ERROR_CODE",
  "error_message": "Human-readable message",
  "calculator_slug": "string",
  "session_id": "uuid",
  "user_id": "uuid or null",
  "tier": "free|pro|ai|b2b",
  "stack_trace": "Full stack trace",
  "context": { /* Additional context */ }
}
```

**Do not log PII** (per Section 5.2):
- ✗ Never log: Email addresses, names, IP addresses (except hashed)
- ✓ Log: session_id (UUID), user_id (UUID), tier, calculator_slug

**Log levels**:
- `error`: Calculation failures, export errors, AI API failures (user-impacting)
- `warn`: Rate limit approaching, slow queries (not user-impacting yet)
- `info`: Successful operations (calculation completed, export generated)
- `debug`: Detailed tracing (only in development, not production)

---

## 2. Performance Monitoring

### Performance Metrics

**1. Calculation Latency**

**What gets measured**:
- **p50 (median)**: Half of calculations complete faster than this
  - Target: <100ms
  - Typical: 80-120ms

- **p95**: 95% of calculations complete faster than this
  - Target: <150ms (per Section 1.6 SLAs)
  - Alert threshold: >500ms

- **p99**: 99% of calculations complete faster than this
  - Target: <300ms
  - Alert threshold: >1000ms

**Per-calculator breakdown**:
| Calculator | p50 | p95 | p99 | Status |
|------------|-----|-----|-----|--------|
| Business Loan DSCR | 95ms | 142ms | 280ms | ✓ Passing |
| Cash Runway | 110ms | 165ms | 310ms | ✓ Passing |
| Breakeven Margin | 85ms | 130ms | 250ms | ✓ Passing |
| Valuation Models | 180ms | 420ms | 850ms | ⚠ Warning (p95 high) |
| Equipment Lease | 90ms | 135ms | 260ms | ✓ Passing |

**Alert**: If Valuation p95 exceeds 500ms, investigate (complex NPV/IRR calculations may need optimization).

**How it's tracked**:
- Measure server-side: Start timer before calculation, end after result computed
- Log response_time_ms in calculator_calculated event
- Aggregate in analytics database (ClickHouse, BigQuery)
- Dashboard: Real-time line chart (p50, p95, p99 over last 24 hours)

---

**2. Export Generation Time**

**What gets measured**:
- **p50 (median)**: Half of exports generate faster than this
  - PDF: 1.8s
  - CSV: 0.4s
  - Excel: 1.5s

- **p95**: 95% of exports generate faster than this
  - PDF: 2.8s (target: <3s per Section 1.6)
  - CSV: 0.7s
  - Excel: 2.4s

- **p99**: 99% of exports generate faster than this
  - PDF: 4.5s (acceptable, rare slow exports)
  - CSV: 1.1s
  - Excel: 3.2s

**Alert thresholds**:
- Warning: p95 PDF generation >6 seconds
- Critical: p95 PDF generation >10 seconds

**How it's tracked**:
- Measure server-side: Start timer at export_requested, end at export_generated
- Log generation_time_ms in export_generated event
- Dashboard: Real-time histogram (distribution of generation times)

---

**3. AI Request Latency**

**What gets measured**:
- **p50 (median)**: Half of AI requests respond faster than this
  - Target: <2s
  - Typical: 1.5-2.5s (depends on LLM provider)

- **p95**: 95% of AI requests respond faster than this
  - Target: <3s (per Section 1.6 SLAs)
  - Alert threshold: >8 seconds

- **p99**: 99% of AI requests respond faster than this
  - Acceptable: <5s
  - Alert threshold: >10 seconds

**Per-request-type breakdown**:
| Request Type | p50 | p95 | p99 | Status |
|--------------|-----|-----|-----|--------|
| explain_result | 1.6s | 2.9s | 4.2s | ✓ Passing |
| suggest_scenario | 3.2s | 7.8s | 11.5s | ⚠ Warning (p95 high) |
| risk_commentary | 2.1s | 3.5s | 5.1s | ✓ Passing |

**Alert**: If suggest_scenario p95 exceeds 8s, investigate (may need prompt optimization or model switch).

**How it's tracked**:
- Measure server-side: Start timer at ai_narrative_requested, end at ai_narrative_displayed
- Log response_time_ms in ai_narrative_displayed event
- Dashboard: Real-time latency distribution (grouped by request type)

---

**4. Page Load Time**

**What gets measured**:
- **First Contentful Paint (FCP)**: When first content renders
  - Target: <1.5s
  - Typical: 1.0-1.8s

- **Time to Interactive (TTI)**: When page is fully interactive
  - Target: <3s
  - Typical: 2.0-3.5s

- **Largest Contentful Paint (LCP)**: When largest content renders
  - Target: <2.5s (Core Web Vitals)

**How it's tracked**:
- Client-side: Web Vitals library (Google)
- Send metrics to analytics via beacon API
- Dashboard: Real-time distribution (FCP, TTI, LCP)

---

**5. Database Query Times**

**What gets measured**:
- **Slow query log**: Queries taking >100ms
  - Log query, duration, table, indexes used
  - Review weekly to identify optimization opportunities

**Example slow query**:
```sql
SELECT * FROM scenarios WHERE user_id = 'uuid' ORDER BY created_at DESC LIMIT 50
-- Duration: 450ms (missing index on user_id)
```

**How it's tracked**:
- PostgreSQL: Enable `log_min_duration_statement = 100` (log queries >100ms)
- Review logs weekly
- Create indexes for frequently slow queries

---

### Performance Monitoring Tools

**Application Performance Monitoring (APM)**:
- **Options**: Datadog APM, New Relic, Elastic APM
- **Capabilities**: Distributed tracing, latency metrics, error tracking, database query analysis
- **Cost**: $15-50/host/month

**Recommended for Phase 1**: Datadog APM (comprehensive, easy setup)

**Key metrics tracked**:
- Calculation latency (p50, p95, p99)
- Export generation time (p50, p95, p99)
- AI request latency (p50, p95, p99)
- Database query times (slow query log)
- API endpoint response times (per-route latency)

---

## 3. Alert Thresholds

### Critical Alerts (Page immediately)

**Error rate >5% in 5 minutes**:
- Condition: (Error count / Total requests) > 0.05 over 5-minute window
- Severity: Critical
- Action: Page on-call engineer via PagerDuty
- Example: 100 calculation errors out of 1,800 requests in 5 minutes

**Database connection pool exhausted**:
- Condition: All database connections in use, new requests queued
- Severity: Critical
- Action: Page on-call engineer, auto-scale database connections if possible
- Impact: API requests fail with "Database unavailable"

**Export generation failure rate >20% in 5 minutes**:
- Condition: (Failed exports / Total export requests) > 0.20 over 5-minute window
- Severity: Critical
- Action: Page on-call engineer, disable export feature if >50% failure

**AI API completely unavailable**:
- Condition: AI success rate <50% in 5 minutes
- Severity: Critical
- Action: Page on-call engineer, enable AI kill switch (suite_ai_enabled = false)

---

### Warning Alerts (Notify via Slack, no page)

**p95 calculation latency >500ms**:
- Condition: p95 latency exceeds 500ms for any calculator over 15-minute window
- Severity: Warning
- Action: Notify engineering Slack channel, investigate during business hours
- Example: Valuation calculator p95 = 520ms (still functional, but slow)

**p95 export generation time >6 seconds**:
- Condition: p95 PDF generation exceeds 6 seconds over 15-minute window
- Severity: Warning
- Action: Notify engineering Slack channel
- Impact: Users wait longer for exports, but still functional

**AI failure rate >10% in 5 minutes**:
- Condition: (AI errors / AI requests) > 0.10 over 5-minute window
- Severity: Warning
- Action: Notify engineering Slack channel
- Example: OpenAI rate limit intermittently hit

**p95 AI latency >8 seconds**:
- Condition: p95 AI response time exceeds 8 seconds over 15-minute window
- Severity: Warning
- Action: Notify engineering Slack channel, investigate prompt optimization

**Slow database queries detected**:
- Condition: >10 queries exceeded 1 second in past hour
- Severity: Warning
- Action: Notify engineering Slack channel, review slow query log

---

### Informational Alerts (Log only, no notification)

**Error rate 1-5% in 5 minutes**:
- Condition: (Error count / Total requests) between 0.01 and 0.05
- Severity: Info
- Action: Log to monitoring dashboard, no alert

**p95 calculation latency 150-500ms**:
- Condition: p95 latency between SLA target (150ms) and warning threshold (500ms)
- Severity: Info
- Action: Log to dashboard, review during weekly performance review

---

### Alert Configuration

**Alert routing**:
- **Critical alerts**: PagerDuty → On-call engineer (phone call, SMS)
- **Warning alerts**: Slack #engineering-alerts channel
- **Info alerts**: Monitoring dashboard only (no notifications)

**On-call rotation**:
- 1-week rotation among backend engineers
- Escalation: If no response in 15 minutes, page engineering manager

**Alert escalation policy**:
1. Page primary on-call engineer
2. If no acknowledgment in 15 minutes, page secondary on-call
3. If no acknowledgment in 30 minutes, page engineering manager

---

## 4. Monitoring Tools

### Recommended Stack

**1. Application Performance Monitoring (APM)**:
- **Tool**: Datadog APM or New Relic
- **Purpose**: Distributed tracing, latency metrics, error tracking
- **Cost**: ~$30/host/month
- **Setup**: Install agent on app servers, auto-instrument requests

**2. Log Aggregation**:
- **Tool**: Elasticsearch + Kibana (self-hosted) or AWS CloudWatch Logs
- **Purpose**: Centralized log storage, search, analysis
- **Cost**: $50-200/month (depends on log volume)
- **Setup**: Ship logs from app servers to log aggregator (JSON format)

**3. Analytics Platform**:
- **Tool**: ClickHouse (self-hosted) or BigQuery (managed)
- **Purpose**: Analytics event storage, fast querying for dashboards
- **Cost**: $100-500/month (depends on event volume)
- **Setup**: Ingest events from application, build dashboards (Section 7.3)

**4. Uptime Monitoring**:
- **Tool**: Pingdom, UptimeRobot, or Datadog Synthetic Monitoring
- **Purpose**: External health checks (ping API endpoints every 1 minute)
- **Cost**: $15-50/month
- **Setup**: Configure health check endpoints, alert on downtime

**5. Alert Routing**:
- **Tool**: PagerDuty or Opsgenie
- **Purpose**: On-call scheduling, escalation policies, alert routing
- **Cost**: $25-50/user/month
- **Setup**: Integrate with monitoring tools (Datadog, CloudWatch)

**6. Error Tracking**:
- **Tool**: Sentry (client-side errors) or Datadog Error Tracking
- **Purpose**: JavaScript exception tracking, client-side error monitoring
- **Cost**: $25-100/month (depends on error volume)
- **Setup**: Install Sentry SDK in React app, auto-capture exceptions

---

### Monitoring Dashboard Layout

**Dashboard 1: Real-Time Health (Grafana)**:
- **Refresh**: Every 5 seconds
- **Panels**:
  - Request rate (requests per second)
  - Error rate (errors per second, stacked by type)
  - p95 latency (calculation, export, AI)
  - Database connection pool usage
  - CPU and memory usage per host

**Dashboard 2: Performance SLAs (Grafana)**:
- **Refresh**: Every 1 minute
- **Panels**:
  - p95 calculation latency (per calculator, target line at 150ms)
  - p95 export generation time (per format, target line at 3s)
  - p95 AI latency (per request type, target line at 3s)
  - SLA compliance gauge (percentage of requests meeting SLA)

**Dashboard 3: Error Analysis (Kibana or Datadog)**:
- **Refresh**: Every 5 minutes
- **Panels**:
  - Error count by type (calculation, export, AI, client)
  - Error rate over time (last 24 hours)
  - Top error messages (most frequent)
  - Errors by calculator (which calculators have most errors)

**Dashboard 4: Business Metrics (Metabase/Tableau)**:
- **Refresh**: Hourly
- **Panels**: See Section 7.3 (Calculator Funnel, Tier Conversion, AI Usage, Export, Scenario)

---

## Summary

This error and performance monitoring strategy provides:

**Error tracking**:
- Calculation engine errors (timeouts, formula failures)
- Export generation errors (PDF rendering, S3 upload failures)
- AI service errors (API timeouts, rate limits)
- Client-side errors (JavaScript exceptions, network failures)
- Structured JSON logging with session_id, user_id, tier context

**Performance monitoring**:
- Calculation latency (p50, p95, p99 per calculator) - target p95 <150ms
- Export generation time (p50, p95, p99 per format) - target p95 <3s
- AI request latency (p50, p95, p99) - target p95 <3s
- Page load time (FCP, TTI, LCP)
- Database query times (slow query log for queries >100ms)

**Alert thresholds**:
- Critical: Error rate >5%, database pool exhausted (page on-call)
- Warning: p95 latency >500ms, AI failure >10% (Slack notification)
- Info: Error rate 1-5%, latency 150-500ms (log only)

**Monitoring tools**:
- APM: Datadog or New Relic (distributed tracing, metrics)
- Logs: Elasticsearch or CloudWatch (centralized log aggregation)
- Analytics: ClickHouse or BigQuery (event storage, dashboards)
- Uptime: Pingdom or UptimeRobot (external health checks)
- Alerts: PagerDuty or Opsgenie (on-call routing)

All monitoring enforces performance SLAs from Section 1.6 with automated alerts when targets are exceeded.
