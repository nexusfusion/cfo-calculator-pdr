# 1.6 Product Quality Goals, SLAs, and Data Retention

## Numerical Correctness and Stability

### Calculations Must Match Reference Models Within ±0.1% Tolerance

Every calculator in the suite must be validated against industry-standard reference models:
- **Reference sources**: Excel-based FP&A templates, published formulas from CFA Institute, AICPA guidance, lender underwriting manuals, or open-source financial libraries (e.g., QuantLib)
- **Golden test scenarios**: Each calculator maintains 50+ test scenarios covering typical use cases, edge cases, and boundary conditions
- **Tolerance**: Numeric outputs must match reference models within **±0.1%** (or better) for all golden scenarios
- **Regression testing**: Formula changes trigger automated side-by-side comparisons (new version vs prior version) to detect drift

This validation ensures that users can trust outputs for high-stakes decisions (board presentations, lender approvals, regulatory filings).

### Edge Cases Handled Gracefully (No NaNs, Infinities, Nonsense)

Calculators must never produce:
- **NaN (Not a Number)**: Invalid arithmetic (e.g., 0/0) must be caught and replaced with error messages or sentinel values
- **Infinity**: Divide-by-zero or overflow conditions must be caught and handled (e.g., "Cannot compute DSCR with zero cash flow")
- **Nonsense outputs**: Negative loan amounts, negative cash runway, DSCR > 1000 (likely input error)

Validation logic should:
- **Reject invalid inputs**: "Interest rate must be between 0% and 50%" (catch typos like 500% instead of 5%)
- **Warn on unusual inputs**: "Loan term of 600 months (50 years) is unusually long. Did you mean 60 months?"
- **Provide fallback messages**: "Unable to calculate NPV due to inconsistent cash flows. Check inputs and try again."

Graceful error handling prevents user confusion and maintains trust in the calculation engine.

---

## Performance SLAs (Internal Targets)

| Metric | Target (p95) | Target (p99) | Notes |
|--------|--------------|--------------|-------|
| **Recalculation latency** | < 150ms | < 500ms | Server-side calculation only; excludes WAN latency and AI generation |
| **Export generation (PDF)** | < 3 seconds | < 6 seconds | Standard single-scenario report (2-5 pages); excludes large multi-scenario exports |
| **Export generation (CSV)** | < 1 second | < 2 seconds | Standard single-scenario export (< 1000 rows) |
| **AI narrative generation** | < 3 seconds | < 8 seconds | Includes LLM API call; hard timeout at 10 seconds with fallback message |
| **End-to-end UI update** | < 300ms | < 500ms | Time from input change to visible output update (modern desktop/tablet, reasonable network) |
| **Low-end device UI update** | < 500ms | < 1 second | Budget Android/iOS devices or slow network; requires loading feedback |

### Server-Side Performance

- **p95 recalculation latency < 150ms**: Typical calculators (equipment loan, DSCR, cash runway) should recalculate in under 150ms for 95% of requests. Complex calculators (multi-year NPV/IRR, Monte Carlo sensitivity) may take longer but should stay under 500ms at p95.
- **p95 export generation < 3 seconds**: Standard single-scenario PDF (2-5 pages) should generate in under 3 seconds. Multi-scenario exports (10+ pages) or large CSV exports (5000+ rows) may require async generation with progress indicators.
- **p99 targets**: Allow for network variability, cold starts, and occasional database latency. p99 targets are 2-4x p95 targets.

### End-to-End UX Performance

- **Visible UI update within 300ms**: Users expect near-instant feedback when changing inputs. On modern devices with reasonable network connections, output tables and charts should update within 300ms of input change.
- **500ms on low-end devices**: Budget smartphones or slow networks may require 500ms-1s. During this time, show a loading spinner or skeleton UI to indicate progress.
- **AI narratives: ~1-3 seconds p95, 6-8 second timeout**: AI commentary should feel responsive, not sluggish. If LLM API call exceeds 10 seconds, abort and show fallback message ("AI commentary unavailable; please try again").

### Large Exports and Async Generation

For exports that exceed standard SLAs (e.g., 20-page multi-scenario PDF, 10,000-row CSV):
- **Progress indicators**: Show "Generating page 3 of 20..." or "Preparing export... 45% complete"
- **Async generation**: Offload to background job queue; email download link when ready
- **Cache results**: If user requests same export again within 24 hours, serve cached version

---

## Reliability and Regression Safety

### Formula Changes Covered by Regression Tests with Golden Scenarios

Every formula change must pass regression testing:
- **Golden scenarios**: Each calculator maintains 50+ test scenarios with known-correct outputs (validated against reference models)
- **Side-by-side comparison**: New formula version outputs are compared to prior version outputs for all golden scenarios
- **Tolerance check**: If outputs differ by more than ±0.1%, the change is flagged for manual review
- **Approval required**: Formula changes that alter outputs (even within tolerance) require explicit approval from product owner or finance SME

This process prevents accidental formula drift and ensures that "bug fixes" don't introduce new errors.

### Automated Test Suites on Each Release

Pre-release checklist:
- **Unit tests**: All calculation functions have unit tests (target: 90%+ code coverage for calculation engine)
- **Integration tests**: End-to-end tests for each calculator (input → calculation → output → export)
- **Golden scenario tests**: Run all golden scenarios and verify outputs match expected values within tolerance
- **UI regression tests**: Visual regression tests for key screens (input forms, output tables, charts, PDFs)

No release ships without passing full test suite.

### Formula and Product Version IDs in Exports

Every export (PDF, CSV) must include:
- **Formula version ID**: e.g., `dscr_v1.3.2`, `npv_v2.1.0`
- **Product version ID**: e.g., `calculator-suite_v1.8.3`
- **Timestamp**: ISO 8601 format (e.g., `2025-03-15T14:22:37Z`)
- **User ID**: Pseudonymous ID (for logged-in users) or session ID (for anonymous users)

This metadata allows users to:
- **Reproduce results**: Rerun the same scenario 6 months later and verify consistency
- **Compare versions**: Understand if differences between two exports are due to formula changes, input changes, or data changes
- **Audit trail**: Provide evidence to auditors, lenders, or regulators that outputs were generated by approved calculation logic

---

## Clarity of Explanation

### Tooltips: Plain Language, No Jargon

Tooltips must be accessible to non-finance users:
- **Bad**: "DSCR = NOI / TDS"
- **Good**: "Debt Service Coverage Ratio (DSCR) measures your ability to cover loan payments from operating income. Lenders typically require 1.25 or higher."

Tooltips should:
- **Define terms**: Don't assume users know what DSCR, NPV, IRR mean
- **Explain why it matters**: "Lenders use this to assess credit risk"
- **Suggest typical values**: "Most lenders require 1.25-1.50"
- **Keep it brief**: 1-3 sentences max; link to help docs for deeper explanations

### Warnings: Direct and Actionable

Warnings should tell users **what's wrong** and **what to do**:
- **Bad**: "DSCR below threshold"
- **Good**: "Your DSCR is 1.18, below the typical lender threshold of 1.25. Consider reducing debt, extending the loan term, or improving cash flow."

Warnings should:
- **State the problem**: "DSCR is 1.18"
- **Provide context**: "Typical lender threshold is 1.25"
- **Suggest action**: "Reduce debt, extend term, or improve cash flow"
- **Use measured tone**: "Consider" not "You must"; "below typical threshold" not "DANGER: UNACCEPTABLE"

Actionable warnings help users make better decisions and build confidence in the tool.

---

## Consistency and Maintainability

### Shared Components (No Copy-Paste)

Calculators must share UI components, calculation libraries, and export templates:
- **UI components**: Input fields, dropdown selectors, chart widgets, export buttons are shared React components
- **Calculation libraries**: Formulas are centralized in a shared TypeScript library, not duplicated per calculator
- **Export templates**: PDF and CSV generation uses shared templates with customizable headers/footers

This consistency:
- **Reduces bugs**: Fix a bug once, not N times
- **Simplifies updates**: Update export format (e.g., add disclaimer) once, propagates to all calculators
- **Improves UX**: Users see familiar patterns across all calculators

### Versioning and Change Logs

Every release must include:
- **Semantic versioning**: `MAJOR.MINOR.PATCH` (e.g., `1.8.3`)
- **Change log**: Public-facing summary of new features, bug fixes, formula changes
- **Formula version tracking**: Internal log of formula version changes (e.g., `dscr_v1.3.1 → dscr_v1.3.2: fixed rounding error in monthly compounding`)

Change logs provide transparency to users and audit trail for compliance.

---

## Data Retention, Logs, and Analytics

### Saved Scenarios: 24 Months Default (SaaS)

- **SaaS default retention**: Saved scenarios are retained for 24 months from last access
- **User deletion**: Users can delete scenarios manually at any time
- **Account closure**: When a user closes their account, scenarios are deleted within 30 days (GDPR/CCPA compliance)
- **Export-only users**: Anonymous users who only generate exports (no saved scenarios) have no scenario retention (exports are deleted after 24 hours)

24-month retention balances user convenience (access to historical scenarios for comparison) with data minimization (don't store data indefinitely).

### Usage Analytics/Logs: 12 Months Default (No PII, Pseudonymous IDs Only)

- **What's logged**: Calculator usage (which calculators, how often), input distributions (loan amount ranges, term ranges), export events (PDF, CSV), AI requests
- **What's NOT logged**: Raw scenario data (specific inputs/outputs), PII (email, IP addresses except hashed for abuse detection), company names
- **Pseudonymous IDs**: User IDs are UUIDs or hashed emails; session IDs for anonymous users
- **Retention**: Logs are auto-purged after 12 months
- **Opt-out**: Users can disable telemetry (loses access to personalized dashboards and tips)

12-month retention provides sufficient data for product analytics (conversion funnels, feature adoption) while limiting liability.

### B2B Deployments: Configurable Retention, Opt-Out Telemetry

B2B clients can configure:
- **Scenario retention**: 7 days to indefinite (client's choice)
- **Log retention**: None (no telemetry) to 24 months
- **Telemetry opt-out**: Disable all usage tracking (client loses dashboard visibility)
- **AI opt-out**: Disable AI features entirely (no LLM calls, no data sent to third-party APIs)

This flexibility makes the suite viable for regulated industries and privacy-conscious clients.

---

**Summary**: The suite targets ±0.1% numeric accuracy versus reference models, handles edge cases gracefully, and meets performance SLAs (p95 recalculation < 150ms, p95 export < 3s). Regression testing, formula versioning, and audit trails ensure reliability. Tooltips and warnings use plain language and actionable guidance. Shared components and versioning ensure maintainability. Data retention defaults to 24 months for scenarios, 12 months for logs (no PII), with configurable opt-outs for B2B clients.
