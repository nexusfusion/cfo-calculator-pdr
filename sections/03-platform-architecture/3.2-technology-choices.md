# 3.2 Technology Choices

This section justifies the technology stack for the CFO Business Intelligence Calculator Suite. Each decision balances development velocity, performance requirements (Section 1.6 SLAs), hosting costs, and team expertise. Alternatives are considered explicitly to document tradeoffs.

---

## Frontend Stack

### React + TypeScript

**Choice**: React 18+ with TypeScript (strict mode)

**Why chosen**:
- **Component reusability**: Calculators share 70-80% of UI components (input forms, result tables, scenario tabs). React's component model fits perfectly.
- **Ecosystem maturity**: Massive library ecosystem for charting (Recharts, Chart.js), forms (React Hook Form), and utilities. Reduces custom development.
- **TypeScript safety**: Strongly typed props and state prevent runtime errors, especially critical for financial calculations where type bugs could produce incorrect results.
- **WordPress compatibility**: React apps can be embedded in WordPress via shortcodes or iframe with minimal friction.
- **Team familiarity**: React is the most common frontend framework; easier to hire and onboard developers.

**Alternatives considered**:
- **Vue.js**: Simpler learning curve but smaller ecosystem, especially for enterprise-grade component libraries.
- **Svelte**: Excellent performance and developer experience but less mature ecosystem and smaller talent pool.
- **Vanilla JS + Web Components**: Maximum performance but slower development velocity and requires building too much infrastructure from scratch.

**Tradeoffs**:
- React bundle size is larger than Svelte (45KB min+gzip for React + ReactDOM). Mitigated by code splitting and CDN caching.
- React's virtual DOM has overhead, but negligible for calculator UI (not rendering 10K+ rows).

---

### State Management: Zustand

**Choice**: Zustand for global state, React Context for localized state

**Why chosen**:
- **Minimal boilerplate**: Zustand requires far less setup than Redux (no actions, reducers, middleware). Faster development.
- **Sufficient for our needs**: We don't need time-travel debugging or complex middleware. State is mostly: current scenario inputs, user tier, saved scenarios list.
- **React Context for UI state**: Tier modal visibility, tooltip open/closed, active tab. No need for global store.
- **TypeScript-first**: Zustand has excellent TypeScript support with minimal type gymnastics.

**Alternatives considered**:
- **Redux Toolkit**: Industry standard, excellent DevTools, but overkill for our use case. Too much boilerplate for simple state updates.
- **React Context only**: Works for small apps but scales poorly. Re-renders too aggressively when context value changes.
- **Jotai/Recoil**: Atomic state management is elegant but less mature and smaller community.

**Tradeoffs**:
- Zustand has smaller ecosystem than Redux (fewer middleware options, less tooling). Acceptable since our state management is straightforward.

---

### Styling: Tailwind CSS

**Choice**: Tailwind CSS with custom design tokens

**Why chosen**:
- **Rapid prototyping**: Utility-first CSS speeds up UI development. No need to name classes or manage CSS files per component.
- **Consistency**: Design tokens (colors, spacing, typography) enforced via Tailwind config. Prevents style drift across calculators.
- **Small bundle size**: PurgeCSS removes unused styles. Typical production bundle: 10-15KB gzipped.
- **Responsive design**: Tailwind's responsive utilities (`md:`, `lg:`) make mobile-first design trivial.

**Alternatives considered**:
- **Material UI (MUI)**: Pre-built components look professional but harder to customize. Bundle size is large (80KB+ min+gzip). Over-engineered for our needs.
- **Styled Components / Emotion**: CSS-in-JS is powerful but adds runtime overhead. Tailwind is build-time, zero runtime cost.
- **Custom CSS/SCSS**: Maximum control but slower development and higher maintenance burden. Style drift across calculators is a real risk.

**Tradeoffs**:
- Tailwind classes can be verbose (`className="flex items-center justify-between px-4 py-2 bg-blue-500 text-white rounded"`). Mitigated by extracting to components.
- Learning curve for developers unfamiliar with utility-first CSS. Worth it for consistency and velocity.

---

## Backend Stack

### Node.js + TypeScript

**Choice**: Node.js 20 LTS with TypeScript (strict mode)

**Why chosen**:
- **Shared language with frontend**: TypeScript on both frontend and backend. Share types (input schemas, API responses) between client and server. Reduces bugs.
- **Performance sufficient for SLAs**: Node.js single-threaded event loop handles I/O-bound workloads (API requests, database queries) efficiently. Calculation engine is CPU-bound but fast enough (<150ms per Section 1.6).
- **NPM ecosystem**: Massive library ecosystem for financial math, PDF generation, LLM clients, etc.
- **Async-first**: Node.js async/await model fits naturally with export queues, AI requests, and database calls.

**Alternatives considered**:
- **Python (FastAPI/Django)**: Excellent for data science and ML but slower raw performance than Node.js. Adds complexity (two languages, separate deployments). NumPy would be overkill for our formulas.
- **Go**: Superior performance (5-10x faster than Node for CPU-bound tasks) but smaller ecosystem for financial libraries, PDF generation. Harder to hire for.
- **Rust**: Best performance and safety but steep learning curve, longer development time, tiny ecosystem for web development.

**Tradeoffs**:
- Node.js single-threaded model struggles with CPU-intensive tasks. If calculations take >150ms consistently, we may offload to Worker Threads or Go microservice. Not expected for Phase 1.

---

### Framework: Fastify

**Choice**: Fastify 4.x

**Why chosen**:
- **Performance**: Fastify is 2-3x faster than Express (20K requests/sec vs 8K in benchmarks). Helps meet p95 latency SLAs.
- **Schema validation built-in**: JSON Schema validation via AJV is first-class (not middleware). Validates all inputs against TypeScript-generated schemas.
- **TypeScript-first**: Excellent TypeScript support with typed route handlers, plugins, decorators.
- **Plugin ecosystem**: Fastify plugins for auth, CORS, rate limiting, WebSockets, etc.

**Alternatives considered**:
- **Express**: Industry standard, huge ecosystem, but slower and lacks built-in schema validation. TypeScript support is mediocre (requires `@types/express`).
- **NestJS**: Batteries-included framework with dependency injection, decorators, etc. Too opinionated and heavy for our needs. Adds complexity without commensurate value.
- **Hono/Bun**: Emerging ultra-fast frameworks but too immature. Small ecosystems, fewer plugins, higher risk.

**Tradeoffs**:
- Fastify ecosystem is smaller than Express (fewer third-party plugins, less Stack Overflow answers). Acceptable given our needs are straightforward.

---

### Hosting: Railway (Phase 1), AWS (Phase 2+)

**Choice**: Railway for Phase 1 MVP, migrate to AWS for Phase 2+ scale

**Why chosen (Railway)**:
- **Zero-config deployments**: Git push → automatic build and deploy. No Kubernetes YAML, no Terraform.
- **Integrated services**: PostgreSQL, Redis, and app hosting in one platform. No service stitching.
- **Cost-effective for MVP**: $5-20/month for small workloads. Scales to $200-500/month for Phase 1 traffic (1K-10K users).
- **Developer experience**: Excellent logs, metrics, environment variables, and rollback UX.

**Why migrate to AWS (Phase 2+)**:
- **Cost at scale**: Railway pricing becomes expensive at >100K requests/day. AWS is cheaper at scale (EC2, Fargate, or Lambda).
- **Advanced features**: AWS offers autoscaling, multi-region, CDN (CloudFront), managed services (RDS, ElastiCache) that Railway lacks or charges premium for.
- **B2B requirements**: Large B2B clients may require SOC 2, HIPAA, or on-premise deployment, which favors AWS or self-hosted Kubernetes.

**Alternatives considered**:
- **Vercel**: Great for Next.js apps but expensive for API hosting ($20/month → $200+/month quickly). Serverless functions have cold start latency (300-500ms), violating our SLAs.
- **Render**: Similar to Railway but slightly slower deployments and less polished UI. Pricing is comparable.
- **AWS from Day 1**: Over-engineered for MVP. Weeks of DevOps work (VPCs, load balancers, RDS setup) before writing code. Use Railway to ship fast, migrate later.

**Tradeoffs**:
- Railway lock-in for Phase 1. Migration to AWS (Phase 2) requires infrastructure rewrite (Docker → ECS/Fargate, Railway DB → RDS). Plan for this as a 2-4 week project.

---

## Databases

### Scenarios Storage: PostgreSQL

**Choice**: PostgreSQL 15+ (Railway PostgreSQL in Phase 1, AWS RDS in Phase 2+)

**Why chosen**:
- **JSONB for flexible schemas**: Scenario inputs/outputs vary per calculator. JSONB columns allow schemaless storage while preserving query-ability (GIN indexes on JSONB fields).
- **Relational integrity**: Users, scenarios, subscriptions have clear relationships. Foreign keys, transactions, ACID guarantees.
- **Mature ecosystem**: ORMs (Prisma, TypeORM), migration tools, backup/restore, performance tuning are all solved problems.
- **Full-text search**: Built-in full-text search for scenario names, descriptions (if needed).

**Alternatives considered**:
- **MongoDB**: JSONB in PostgreSQL gives us 90% of MongoDB's flexibility with better relational integrity and transaction support. Mongo adds operational complexity (replica sets, sharding).
- **MySQL**: Comparable to PostgreSQL but weaker JSONB support (JSON columns less feature-rich). PostgreSQL is preferred by developers.
- **DynamoDB**: Excellent for key-value workloads but poor for relational queries (no joins, limited indexes). Overkill for our schema.

**Tradeoffs**:
- PostgreSQL vertical scaling is limited (single-node writes). If we exceed 10K writes/sec, we'll need read replicas or sharding. Not expected until Phase 3+ (100K+ users).

---

### Sessions and Cache: Redis

**Choice**: Redis 7+ (Upstash in Phase 1, AWS ElastiCache in Phase 2+)

**Why chosen**:
- **Session storage**: TTL-based session expiry (24 hours anonymous, 30 days logged-in) is Redis's sweet spot.
- **Rate limiting**: Redis INCR + EXPIRE for rate limit counters (per-user, per-IP, per-API-key). Sub-millisecond latency.
- **Cache**: Calculation results cached by input hash (5-minute TTL). Export file URLs cached (1-hour TTL).
- **Pub/Sub (optional)**: WebSocket notifications (export ready, AI narrative ready) via Redis Pub/Sub.

**Alternatives considered**:
- **In-memory cache (Node.js process)**: Fast but not shared across API server instances. Cache misses when load balancer routes to different server.
- **Memcached**: Simpler than Redis but lacks TTL per key, no Pub/Sub, no persistence. Redis is more versatile for same cost.
- **PostgreSQL for sessions**: Possible but slower (disk I/O vs in-memory). Redis is purpose-built for this.

**Tradeoffs**:
- Redis is another dependency to manage (more failure modes). Mitigated by using managed service (Upstash, ElastiCache).
- Redis data is ephemeral (lost on restart unless persistence enabled). Acceptable for sessions and cache; permanent data goes to PostgreSQL.

---

### Analytics Storage: PostgreSQL (Phase 1), ClickHouse (Phase 2+)

**Choice**: PostgreSQL with time-series table (Phase 1), migrate to ClickHouse for high-volume analytics (Phase 2+)

**Why chosen (PostgreSQL Phase 1)**:
- **Reuse existing database**: One less service to manage. Analytics events are low-volume in MVP (<10K events/day).
- **Partitioned tables**: PostgreSQL table partitioning by month (e.g., `events_2025_01`, `events_2025_02`) handles time-series data efficiently.
- **Retention policy**: Drop old partitions after 12 months (per Section 1.6) with simple `DROP TABLE` command.

**Why migrate to ClickHouse (Phase 2+)**:
- **High-volume analytics**: ClickHouse handles 100K-1M events/day with sub-second query times (vs PostgreSQL which slows down at 1M+ rows).
- **Columnar storage**: Analytics queries (GROUP BY, aggregations) are 10-100x faster on columnar databases.
- **Cost-effective**: ClickHouse compresses data aggressively (10:1 ratios), reducing storage costs.

**Alternatives considered**:
- **BigQuery / Snowflake**: Excellent for analytics but expensive for small workloads ($100+/month). Overkill for Phase 1.
- **Elasticsearch**: Good for logs and full-text search but overkill for structured analytics events. Higher operational complexity.

**Tradeoffs**:
- ClickHouse is complex to operate (replication, sharding, backups). Use managed service (ClickHouse Cloud, Altinity) or defer to Phase 2+.

---

## Message Queue

### BullMQ (Redis-backed)

**Choice**: BullMQ 4.x (uses Redis as backend)

**Why chosen**:
- **Redis-backed**: Reuses existing Redis infrastructure. No additional service to manage.
- **Job priorities**: Export jobs can be prioritized (Pro tier exports prioritized over Free tier).
- **Retries and DLQ**: Automatic retries on failure, dead-letter queue for failed jobs.
- **Rate limiting**: Limit concurrent export workers (e.g., max 10 PDF generations at once).
- **Dashboard**: Bull Board provides web UI for monitoring queues, jobs, failures.

**Alternatives considered**:
- **AWS SQS**: Fully managed, zero operational overhead, but higher latency (100-200ms per message vs <10ms for Redis). Adds AWS dependency in Phase 1.
- **RabbitMQ**: More powerful (complex routing, guaranteed delivery) but over-engineered for our needs. Higher operational complexity (clustering, disk management).
- **Kafka**: Extreme overkill. Kafka is for high-throughput event streaming (1M+ events/sec), not job queues.

**Tradeoffs**:
- BullMQ depends on Redis availability. If Redis is down, job queue is down. Mitigated by using managed Redis with high availability.

---

## File Storage

### Cloudflare R2 (S3-compatible)

**Choice**: Cloudflare R2 for export files (PDFs, CSVs)

**Why chosen**:
- **Zero egress fees**: S3 charges $0.09/GB for egress (downloads). R2 is zero egress. Significant savings if users download many exports.
- **S3-compatible API**: Drop-in replacement for AWS S3 SDK. Easy migration path if needed.
- **Integrated CDN**: Cloudflare's CDN caches export files at edge, reducing latency for repeated downloads.
- **Pricing**: $0.015/GB storage (vs S3 $0.023/GB). Cheaper for large export archives.

**Alternatives considered**:
- **AWS S3**: Industry standard, deeper integration with AWS services (Lambda, CloudFront). Slightly more expensive, egress fees.
- **Backblaze B2**: Cheaper than R2 ($0.005/GB storage) but slower (no edge CDN), less integration with dev tools.
- **Local file storage (server disk)**: Cheap but not durable (server crashes lose files), not scalable (fills disk).

**Tradeoffs**:
- Cloudflare R2 is newer (launched 2022), less mature than S3. Acceptable risk given S3-compatible API makes migration easy.

---

## CDN

### Cloudflare CDN

**Choice**: Cloudflare CDN for static assets (JavaScript bundles, CSS, images) and export files

**Why chosen**:
- **Free tier**: Cloudflare CDN is free for unlimited bandwidth. S3 + CloudFront costs $0.085/GB.
- **Global edge network**: 300+ PoPs worldwide. Static assets served from nearest edge location (20-50ms latency vs 200ms cross-continent).
- **Cache-Control headers**: Control cache TTL per asset type (JavaScript bundles: 1 year, HTML: 5 minutes).
- **DDoS protection**: Cloudflare's DDoS protection is built-in (vs AWS Shield which costs extra).

**Alternatives considered**:
- **AWS CloudFront**: Deeper AWS integration but $0.085/GB egress. Expensive at scale.
- **Fastly**: Excellent performance, real-time cache purging, but expensive ($50/month minimum, $0.12/GB).
- **No CDN**: Serve assets from origin server. Higher latency (200ms+ for international users), higher origin load.

**Tradeoffs**:
- Cloudflare free tier has some limitations (cache purge rate limits, no advanced routing rules). Acceptable for Phase 1.

---

## Summary Table

| Layer | Technology | Why Chosen | Phase 2+ Alternative |
|-------|-----------|------------|---------------------|
| **Frontend** | React + TypeScript + Zustand + Tailwind | Component reuse, type safety, rapid development | Consider Vue/Svelte if React bundle size becomes issue |
| **Backend** | Node.js + TypeScript + Fastify | Shared language, sufficient performance, fast development | Migrate hot paths to Go if <150ms SLA violated |
| **Hosting** | Railway (Phase 1) | Zero-config, cost-effective for MVP | AWS (ECS/Fargate/Lambda) for scale and B2B requirements |
| **Database (scenarios)** | PostgreSQL + JSONB | Relational integrity, flexible schema, mature | Add read replicas if >10K writes/sec |
| **Database (sessions/cache)** | Redis | TTL, rate limiting, sub-ms latency | ElastiCache or Redis Enterprise for HA |
| **Database (analytics)** | PostgreSQL (Phase 1) | Reuse existing DB, low volume | ClickHouse or BigQuery for >100K events/day |
| **Message Queue** | BullMQ (Redis-backed) | Job priorities, retries, Redis reuse | AWS SQS or RabbitMQ if Redis becomes bottleneck |
| **File Storage** | Cloudflare R2 | Zero egress fees, S3-compatible | AWS S3 if tighter AWS integration needed |
| **CDN** | Cloudflare | Free, global edge, DDoS protection | CloudFront if already on AWS |

---

## Migration Strategy

**Phase 1 → Phase 2 infrastructure migration** (when traffic exceeds Railway capacity, ~50K+ DAU):
1. Set up AWS account, VPC, load balancers, RDS (PostgreSQL), ElastiCache (Redis)
2. Containerize application (Docker) and deploy to AWS ECS or Fargate
3. Migrate PostgreSQL data from Railway to AWS RDS (pg_dump → pg_restore, test thoroughly)
4. Update DNS to point to AWS load balancer
5. Keep Railway as staging/dev environment or decommission
6. Estimated migration time: 2-4 weeks with 2 engineers

**Technology upgrades** (ongoing):
- Node.js: Upgrade to LTS versions (18 → 20 → 22) annually
- React: Upgrade major versions (18 → 19) when stable
- PostgreSQL: Upgrade minor versions (15.x → 15.y) quarterly, major versions (15 → 16) annually with testing
- Dependencies: Weekly automated dependency updates via Dependabot, security patches applied within 48 hours
