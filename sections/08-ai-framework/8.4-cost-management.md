# 8.4 Cost Management Considerations

This section defines AI cost expectations, usage caps, optimization strategies, and provider selection for the CFO Business Intelligence Calculator Suite. Effective AI cost management ensures healthy margins on the AI tier ($20/month add-on) while maintaining high-quality responses.

---

## AI Cost Philosophy

**Guiding principle**: AI is a **profit center**, not a cost burden

**Target economics**:
- AI tier pricing: $20/month per user (add-on to Pro at $29/month)
- AI COGS (cost of goods sold): <$2/user/month (10% of revenue)
- Target margin: >90% on AI tier revenue

**Cost levers**:
- Usage caps (50 requests/month hard limit)
- Prompt optimization (shorter prompts = lower cost)
- Response caching (reuse responses for identical inputs)
- Prompt caching (reuse system prompts across requests)
- Provider selection (Claude Sonnet vs Haiku vs GPT-4)

---

## 1. Per-Calculator AI Budget

### Expected AI requests per session

Users typically make 1-2 AI requests per calculator session (not 50 requests in one session, but spread over a month).

**Lending calculators** (DSCR, amortization):
- **Explain DSCR**: 1 request per session (most common)
- **Explain total cost**: 1 request per session (less common)
- **Suggest scenarios**: 1 request per session (occasional)
- **Average**: 1.5 requests per session

**Cash flow calculators** (runway, burn rate):
- **Explain runway**: 1 request per session
- **Suggest cost cuts**: 1 request per session (less common)
- **Average**: 1.2 requests per session

**Profitability calculators** (margin, breakeven):
- **Explain margin**: 1 request per session
- **Pricing suggestions**: 1 request per session (occasional)
- **Average**: 1.3 requests per session

**Valuation calculators** (DCF, multiples):
- **Explain valuation range**: 1 request per session
- **Suggest value drivers**: 1 request per session (less common)
- **Average**: 1.4 requests per session

**Average across all calculators**: 1.3-1.5 requests per session

### Token usage per request

AI cost is determined by **tokens consumed** (input tokens + output tokens).

**Prompt tokens** (system + user):
- System prompt: 150-250 tokens (role definition, constraints, disclaimers)
- User prompt: 150-250 tokens (inputs, outputs, question)
- **Total input**: 300-500 tokens per request

**Completion tokens** (AI response):
- Explanation (150-250 words): 200-300 tokens
- Suggestion (50-100 words × 3): 150-250 tokens
- **Total output**: 200-300 tokens per request

**Total tokens per request**: 500-800 tokens

**Example** (DSCR explanation):
```
System prompt: 180 tokens
User prompt: 220 tokens
AI response: 250 tokens
Total: 650 tokens
```

### Cost per request (Claude API pricing)

**Anthropic Claude Sonnet 4 pricing** (as of 2025):
- Input tokens: $3 per million tokens
- Output tokens: $15 per million tokens

**Cost calculation**:
```
Input cost: 500 tokens × $3 / 1,000,000 = $0.0015
Output cost: 300 tokens × $15 / 1,000,000 = $0.0045
Total cost per request: $0.006 (0.6 cents)
```

**With prompt caching** (90% reduction on system prompt):
```
Cached system prompt: 180 tokens × $0.30 / 1,000,000 = $0.00005 (90% discount)
Non-cached user prompt: 220 tokens × $3 / 1,000,000 = $0.00066
Output cost: 300 tokens × $15 / 1,000,000 = $0.0045
Total cost per request: $0.0052 (0.52 cents, 13% cheaper)
```

**Average cost per request**: **$0.005-$0.006** (0.5-0.6 cents)

---

## 2. Usage Caps and Throttling

To ensure predictable costs and prevent abuse, AI tier includes a **hard cap** of 50 requests per user per month.

### Request limits by tier

| Tier | AI Requests/Month | Overage Handling |
|------|-------------------|------------------|
| Free | 0 (disabled) | Upgrade prompt shown |
| Pro | 0 (disabled) | Upgrade prompt shown |
| AI | 50 (hard cap) | "Quota exceeded" message |
| B2B | Custom (e.g., 500) | Configurable per tenant |

### Quota enforcement

**Implementation**:
```typescript
interface UserAIUsage {
  user_id: string;
  month: string; // Format: "2025-11"
  requests_used: number;
  requests_limit: number; // 50 for AI tier
  last_request_at: string; // ISO timestamp
}

async function canMakeAIRequest(userId: string): Promise<boolean> {
  const currentMonth = new Date().toISOString().slice(0, 7); // "2025-11"
  const usage = await db.getUserAIUsage(userId, currentMonth);

  if (!usage) {
    // First request this month, create record
    await db.createUserAIUsage(userId, currentMonth, 1, 50);
    return true;
  }

  if (usage.requests_used >= usage.requests_limit) {
    // Quota exceeded
    return false;
  }

  // Increment counter
  await db.incrementAIUsage(userId, currentMonth);
  return true;
}
```

**Database table**:
```sql
CREATE TABLE user_ai_usage (
  user_id UUID NOT NULL,
  month VARCHAR(7) NOT NULL, -- "2025-11"
  requests_used INTEGER DEFAULT 0,
  requests_limit INTEGER DEFAULT 50,
  last_request_at TIMESTAMP,
  PRIMARY KEY (user_id, month)
);

CREATE INDEX idx_user_ai_usage_month ON user_ai_usage(month);
```

### Quota exceeded handling

**When user hits 50 requests**:

**UI message**:
```
You've used all 50 AI requests this month.

Your limit resets on December 1, 2025.

Options:
- Wait until next month (your quota resets automatically)
- Contact sales for higher limits (100 requests for $35/month, 200 for $60/month)
```

**No pay-per-use overage in v1**:
- Users cannot pay for individual additional requests (too complex for v1)
- Phase 2+: Consider overage pricing (e.g., $0.50 per request beyond quota)

**Higher-tier plans** (future):
- AI Plus tier: 100 requests/month for $35/month
- AI Pro tier: 200 requests/month for $60/month
- Unlimited tier: No quota, pay-per-use at $0.10/request

### Request counter visibility

**Display in UI**:
```
AI Requests: 23 of 50 used this month
Resets on December 1, 2025
```

**Location**:
- Account settings page (`/settings/billing`)
- Tooltip when hovering over "Explain this result" button

---

## 3. Cost Optimization Strategies

### Prompt Caching

**What is prompt caching**:
- Anthropic API supports caching system prompts (same across all users)
- Cached prompts cost 90% less ($0.30 per million tokens instead of $3)
- Cache TTL: 5 minutes (reused if another request within 5 minutes)

**Implementation**:
```typescript
const response = await anthropic.messages.create({
  model: 'claude-sonnet-4',
  max_tokens: 400,
  system: [
    {
      type: 'text',
      text: systemPrompt, // This will be cached
      cache_control: { type: 'ephemeral' },
    },
  ],
  messages: [
    { role: 'user', content: userPrompt }, // Not cached (user-specific)
  ],
});
```

**Expected cache hit rate**: 80-90% (system prompts are identical across requests)

**Cost savings**:
- Without caching: $0.006 per request
- With caching (90% hit rate): $0.0052 per request
- **Savings**: 13% reduction in AI costs

### Response Caching

**What is response caching**:
- Cache AI responses for identical inputs (same calculator, same values)
- Serve cached response instead of calling AI API
- Cache TTL: 1 hour (balance freshness vs cost)

**Cache key**:
```typescript
function generateCacheKey(
  calculatorSlug: string,
  inputs: Record<string, any>,
  requestType: string
): string {
  // Sort inputs for consistent hashing
  const sortedInputs = JSON.stringify(inputs, Object.keys(inputs).sort());
  const key = `${calculatorSlug}:${requestType}:${hash(sortedInputs)}`;
  return key;
}

// Example: "business-loan-dscr:explain_result:a1b2c3d4"
```

**Implementation** (Redis cache):
```typescript
async function getAIResponse(
  calculatorSlug: string,
  inputs: Record<string, any>,
  requestType: string
): Promise<string> {
  const cacheKey = generateCacheKey(calculatorSlug, inputs, requestType);

  // Check cache first
  const cached = await redis.get(cacheKey);
  if (cached) {
    console.log('AI response cache hit');
    return cached;
  }

  // Cache miss, call AI API
  const response = await callAIAPI(calculatorSlug, inputs, requestType);

  // Cache response for 1 hour
  await redis.set(cacheKey, response, 'EX', 3600);

  return response;
}
```

**Expected cache hit rate**: 20-30%

**Rationale**:
- Many users test similar scenarios (e.g., $250k loan at 7.5% for 10 years)
- Especially common for "round number" inputs (e.g., $100k, $500k, 5%, 10%)
- Cache hit rate increases during onboarding (many users try demo scenarios)

**Cost savings**:
- Cache hit rate: 25%
- 25% of requests avoid AI API call (zero cost)
- **Savings**: 25% reduction in AI costs

**Combined savings** (prompt caching + response caching):
- Prompt caching: 13% reduction
- Response caching: 25% reduction
- **Total savings**: ~35% reduction (from $0.006 to $0.004 per request)

### Batching Requests

**Not applicable for real-time UI interactions**:
- Users expect AI responses within 2-3 seconds (per Section 1.6 SLAs)
- Batching would introduce latency (wait for batch to fill before processing)

**Future use case** (async report generation):
- Phase 3+: Generate AI-powered monthly summary reports for all users
- Batch 1,000 requests, send to AI API in parallel
- Cost: Same as individual requests, but easier to manage/monitor

---

## 4. AI Provider Selection and Fallback

### Primary provider: Anthropic Claude

**Model**: Claude Sonnet 4

**Why Claude**:
- **High quality**: CFO-grade responses, appropriate hedging language, professional tone
- **Fast**: p95 latency <3 seconds (meets SLAs in Section 1.6)
- **Reliable**: 99.9% uptime, rare rate limit issues
- **Prompt caching**: Built-in support, 90% cost reduction on system prompts

**Cost**:
- $3 per million input tokens
- $15 per million output tokens
- **Average**: $0.006 per request (0.6 cents)

### Alternative: Claude Haiku (lower cost)

**Model**: Claude Haiku 4

**Why Haiku**:
- **Much cheaper**: $0.25 input / $1.25 output (83% cheaper than Sonnet)
- **Fast**: Even faster than Sonnet (p50 <1 second)
- **Acceptable quality**: Good for simple explanations (e.g., "What does DSCR mean?")

**Cost**:
- $0.25 per million input tokens
- $1.25 per million output tokens
- **Average**: $0.001 per request (0.1 cents, 83% cheaper than Sonnet)

**Tradeoff**:
- Lower quality for complex prompts (valuation explanations, risk commentary)
- Less consistent tone (may occasionally use overly casual language)

**Recommendation**: Use Haiku for simple requests (metric definitions), Sonnet for complex requests (risk analysis, scenario suggestions)

**Implementation**:
```typescript
function selectModel(requestType: string): string {
  const simpleRequests = ['metric_definition', 'term_explanation'];
  if (simpleRequests.includes(requestType)) {
    return 'claude-haiku-4'; // Cheaper model for simple tasks
  }
  return 'claude-sonnet-4'; // Default to Sonnet for quality
}
```

**Cost savings**:
- 30% of requests use Haiku (simple explanations)
- 70% of requests use Sonnet (complex analysis)
- **Blended cost**: (0.3 × $0.001) + (0.7 × $0.006) = $0.0045 per request
- **Savings**: 25% reduction vs Sonnet-only

### Fallback provider: OpenAI GPT-4

**Model**: GPT-4 Turbo

**Use case**: Fallback if Anthropic API is down or rate-limited

**Why GPT-4**:
- **High availability**: Multiple regions, rarely down
- **Good quality**: Comparable to Claude Sonnet for financial explanations
- **Familiar**: Well-documented, easy to integrate

**Cost**:
- $10 per million input tokens
- $30 per million output tokens
- **Average**: $0.014 per request (2.3× more expensive than Claude)

**Tradeoff**:
- More expensive (only use as fallback, not primary)
- Different tone/style (may require prompt adjustments)

**Fallback strategy**:
```typescript
async function callAIAPI(prompt: string): Promise<string> {
  try {
    // Try Anthropic first
    return await callAnthropicAPI(prompt);
  } catch (error) {
    if (error.status === 503 || error.status === 429) {
      // Anthropic unavailable or rate-limited, fallback to OpenAI
      console.warn('Anthropic unavailable, using GPT-4 fallback');
      return await callOpenAIAPI(prompt);
    }
    throw error;
  }
}
```

**Alternative fallback**: Show error message instead of calling expensive fallback

**Error message**:
```
AI is temporarily unavailable. Please try again in a few minutes.

Your AI request quota has not been consumed.
```

**Rationale**: Avoid 2.3× cost increase for rare downtime (Anthropic uptime is 99.9%)

---

## 5. Monthly Cost Projections

### Assumptions

**User base**:
- 1,000 active AI tier users (paying $20/month each)

**Usage per user**:
- Average 30 requests per user per month (60% of 50-request cap)
- Some users use all 50 (power users), some use 10 (occasional users)

**Total requests**:
- 1,000 users × 30 requests = 30,000 AI requests per month

**Cost per request**:
- Optimized cost (prompt caching + response caching + Haiku for simple requests): $0.004

### Cost calculation

**Total monthly AI cost**:
```
30,000 requests × $0.004 per request = $120
```

**Revenue from AI tier**:
```
1,000 users × $20/month = $20,000
```

**AI COGS as percentage of revenue**:
```
$120 / $20,000 = 0.6% (very healthy margin)
```

**Gross margin on AI tier**:
```
($20,000 - $120) / $20,000 = 99.4%
```

### Sensitivity analysis

| Scenario | Users | Requests/User | Total Requests | Cost/Request | Total Cost | Revenue | COGS % | Margin |
|----------|-------|---------------|----------------|--------------|------------|---------|--------|--------|
| Base case | 1,000 | 30 | 30,000 | $0.004 | $120 | $20,000 | 0.6% | 99.4% |
| High usage | 1,000 | 50 (cap) | 50,000 | $0.004 | $200 | $20,000 | 1.0% | 99.0% |
| No caching | 1,000 | 30 | 30,000 | $0.006 | $180 | $20,000 | 0.9% | 99.1% |
| Sonnet-only | 1,000 | 30 | 30,000 | $0.006 | $180 | $20,000 | 0.9% | 99.1% |
| GPT-4 fallback | 1,000 | 30 | 30,000 | $0.014 | $420 | $20,000 | 2.1% | 97.9% |
| 10,000 users | 10,000 | 30 | 300,000 | $0.004 | $1,200 | $200,000 | 0.6% | 99.4% |

**Insights**:
- Even in worst case (GPT-4 only, no caching, high usage), COGS is <3% (healthy margin)
- AI tier is extremely profitable (>97% gross margin in all scenarios)
- Scale linearly (10,000 users = $1,200 cost, $200k revenue, same 0.6% COGS)

### Break-even analysis

**At what usage level does AI tier become unprofitable?**

**Formula**:
```
Break-even: Cost per request × Requests per user per month = $20 revenue per month
```

**Calculation**:
```
$20 / $0.004 per request = 5,000 requests per user per month
```

**Interpretation**: User would need to make **5,000 AI requests per month** (100× the 50-request cap) for AI tier to break even. This is impossible due to hard cap, so **AI tier is always profitable**.

---

## 6. Cost Monitoring and Alerts

### Real-time cost tracking

**Track AI spend in real-time** (per Section 7.4 monitoring):

**Metrics**:
- Total AI requests per hour/day/month
- Total AI cost per hour/day/month
- Cost per user (total cost / active AI tier users)
- Average cost per request (should be ~$0.004-$0.006)

**Dashboard** (Grafana or similar):
```
AI Cost Dashboard
┌─────────────────────────────────────┐
│ Total Requests (Last 24h): 1,245    │
│ Total Cost (Last 24h):     $5.23    │
│ Cost per Request:          $0.0042  │
│ Active AI Users:           1,032    │
│ Cost per User (Month):     $0.12    │
└─────────────────────────────────────┘
```

### Cost alerts

**Warning alert**: AI spend >$500/month (expected: $120-200)
- **Action**: Investigate unusual usage (possible abuse, quota enforcement failure)
- **Notification**: Slack #engineering-alerts

**Critical alert**: AI spend >$1,000/month (10× expected)
- **Action**: Page on-call engineer, disable AI features if abuse detected
- **Notification**: PagerDuty

**Cache performance alert**: Response cache hit rate <10% (expected: 20-30%)
- **Action**: Investigate cache invalidation issues, verify Redis uptime
- **Notification**: Slack #engineering-alerts

---

## Summary

AI cost management for the CFO Business Intelligence Calculator Suite:

**Expected costs**:
- $0.004-$0.006 per AI request (0.4-0.6 cents)
- 30 requests per user per month (average)
- $120 total AI cost per month (1,000 AI tier users)

**Revenue**:
- $20/month per AI tier user
- $20,000 total revenue per month (1,000 users)
- **COGS**: 0.6% (AI cost / revenue)
- **Gross margin**: 99.4%

**Usage caps**:
- 50 requests per month (hard cap, AI tier)
- Custom quotas for B2B (e.g., 500 requests)
- No pay-per-use overage in v1 (future: $0.50/request beyond quota)

**Cost optimization**:
- Prompt caching: 13% savings (reuse system prompts)
- Response caching: 25% savings (reuse responses for identical inputs)
- Model selection: 25% savings (Haiku for simple requests, Sonnet for complex)
- **Total savings**: ~50% reduction (from $0.006 to $0.004 per request)

**Provider selection**:
- Primary: Anthropic Claude Sonnet 4 ($0.006/request, high quality)
- Alternative: Claude Haiku 4 ($0.001/request, 83% cheaper, good for simple tasks)
- Fallback: OpenAI GPT-4 ($0.014/request, use only if Anthropic down)

**Cost monitoring**:
- Real-time dashboard (requests, cost, cost per user)
- Alert if spend >$500/month (expected: $120)
- Page on-call if spend >$1,000/month (10× expected)

AI tier is **extremely profitable** (>97% gross margin in all scenarios, even worst case).
